{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yelp data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "\n",
    "This script demonstrates how to split a large JSON file into multiple smaller JSON files. Splitting large files can be beneficial when dealing with memory constraints or distributing computational workloads across multiple environments or processes. Below is a step-by-step breakdown of the code:\n",
    "\n",
    "1. **Import and Variable Setup**  \n",
    "   - `input_file`: The name of the large JSON file to split.  \n",
    "   - `output_prefix`: The prefix used for naming the output files.  \n",
    "   - `num_files`: The number of smaller files to create.\n",
    "\n",
    "2. **Counting Lines**  \n",
    "   - The code opens the input file in read mode and counts how many lines (each containing a JSON object) are present.\n",
    "   - This count determines how many lines each split file will contain (`lines_per_file`).\n",
    "\n",
    "3. **Splitting into Smaller Files**  \n",
    "   - For each split file, the script opens a new file in write mode.  \n",
    "   - It then reads `lines_per_file` lines from the input file and writes them into the new output file.  \n",
    "   - This process repeats for the specified number of files (`num_files`).\n",
    "\n",
    "4. **Stopping Condition**  \n",
    "   - If the file ends before we have written the full `lines_per_file` lines (e.g., the file length is not perfectly divisible), the script stops reading and moves on.\n",
    "\n",
    "5. **Final Output**  \n",
    "   - After the loop completes, the script prints a success message indicating that the large file has been split successfully into the designated smaller files.\n",
    "\n",
    "**Use Case**:  \n",
    "You can use this script when you need to handle extremely large datasets that may exceed system memory limits or require parallel processing. This step helps in efficiently processing, transferring, or analyzing data without having to manage a single massive file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 6990280, Lines per file: 699028\n",
      "✅ JSON file successfully split into smaller parts!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"yelp_academic_dataset_review.json\"  # 5GB JSON file\n",
    "output_prefix = \"split_file_\"  # Prefix for output files\n",
    "num_files = 10  # Number of files to split into\n",
    "\n",
    "# Count total lines (objects) in the file\n",
    "with open(input_file, \"r\" , encoding=\"utf8\") as f:\n",
    "    total_lines = sum(1 for _ in f)  \n",
    "\n",
    "lines_per_file = total_lines // num_files  # Lines per split file\n",
    "\n",
    "print(f\"Total lines: {total_lines}, Lines per file: {lines_per_file}\")\n",
    "\n",
    "# Now split into multiple smaller files\n",
    "with open(input_file, \"r\" , encoding=\"utf8\") as f:\n",
    "    for i in range(num_files):\n",
    "        output_filename = f\"{output_prefix}{i+1}.json\"\n",
    "        \n",
    "        with open(output_filename, \"w\", encoding=\"utf8\" ) as out_file:\n",
    "            for j in range(lines_per_file):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break  # Stop if file ends early\n",
    "                out_file.write(line)\n",
    "\n",
    "print(\"✅ JSON file successfully split into smaller parts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
